{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e523aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai PyMuPDF faiss-cpu numpy python-dotenv langchain langchain-openai langchain-community tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75588b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of root directories containing PDFs\n",
    "root_folders = [\n",
    "        \"folder1\",\n",
    "        \"fodler2\"\n",
    "    ]  # Replace with your actual folders\n",
    "\n",
    "pdf_files = []\n",
    "for root_folder in root_folders:\n",
    "    found_pdfs = glob.glob(os.path.join(root_folder, \"**/*.pdf\"), recursive=True)\n",
    "    pdf_files.extend(found_pdfs)\n",
    "\n",
    "print(f\"Discovered {len(pdf_files)} PDFs:\")\n",
    "for pdf_file in pdf_files:\n",
    "    print(f\"- {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6293f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = ''\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "def process_pdfs(pdf_files):\n",
    "    chunks, sources = [], []\n",
    "    for pdf_file in pdf_files:\n",
    "        text = extract_pdf_text(pdf_file)\n",
    "        pdf_chunks = chunk_text(text)\n",
    "        chunks.extend(pdf_chunks)\n",
    "        sources.extend([pdf_file] * len(pdf_chunks))\n",
    "    return chunks, sources\n",
    "\n",
    "def init_db(db_name=\"chunks.db\"):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS chunks (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            source TEXT,\n",
    "            chunk TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "def store_chunks(conn, chunks, sources):\n",
    "    c = conn.cursor()\n",
    "    c.executemany(\"INSERT INTO chunks (source, chunk) VALUES (?, ?)\", zip(sources, chunks))\n",
    "    conn.commit()\n",
    "\n",
    "conn = init_db()\n",
    "chunks, sources = process_pdfs(pdf_files)\n",
    "store_chunks(conn, chunks, sources)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Processed and stored chunks from {len(pdf_files)} PDFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "def batch_embeddings(chunks, metadatas, batch_size=100):\n",
    "    vectorstore = None\n",
    "    for i in tqdm(range(0, len(chunks), batch_size), desc=\"Creating embeddings\"):\n",
    "        chunk_batch = chunks[i:i+batch_size]\n",
    "        metadata_batch = metadatas[i:i+batch_size]\n",
    "\n",
    "        if vectorstore is None:\n",
    "            vectorstore = FAISS.from_texts(chunk_batch, embeddings_model, metadatas=metadata_batch)\n",
    "        else:\n",
    "            vectorstore.add_texts(chunk_batch, metadatas=metadata_batch)\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "metadata_list = [{\"source\": source} for source in sources]\n",
    "\n",
    "vectorstore = batch_embeddings(chunks, metadata_list, batch_size=100)\n",
    "\n",
    "vectorstore.save_local(\"faiss_index_directory\")\n",
    "\n",
    "print(\"FAISS vectorstore and metadata successfully saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e523aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai PyMuPDF faiss-cpu python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d75588b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import faiss\n",
    "import sqlite3\n",
    "import pickle\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_dotenv()  # to load OPENAI_API_KEY from .env file\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab17ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = ''\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "def process_pdfs(pdf_files):\n",
    "    chunks, sources = [], []\n",
    "    for pdf_file in pdf_files:\n",
    "        text = extract_pdf_text(pdf_file)\n",
    "        pdf_chunks = chunk_text(text)\n",
    "        chunks.extend(pdf_chunks)\n",
    "        sources.extend([pdf_file] * len(pdf_chunks))\n",
    "    return chunks, sources\n",
    "\n",
    "def init_db(db_name=\"chunks.db\"):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS chunks (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            source TEXT,\n",
    "            chunk TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "def store_chunks(conn, chunks, sources):\n",
    "    c = conn.cursor()\n",
    "    c.executemany(\"INSERT INTO chunks (source, chunk) VALUES (?, ?)\", zip(sources, chunks))\n",
    "    conn.commit()\n",
    "\n",
    "def retrieve_chunks(conn):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT id, source, chunk FROM chunks\")\n",
    "    return c.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6293f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text_chunks, model=\"text-embedding-3-small\"):\n",
    "    embeddings = []\n",
    "    for chunk in text_chunks:\n",
    "        response = client.embeddings.create(input=[chunk], model=model)\n",
    "        embeddings.append(response.data[0].embedding)\n",
    "    return np.array(embeddings, dtype='float32')\n",
    "\n",
    "def store_embeddings(embeddings, file_name=\"faiss.index\"):\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, file_name)\n",
    "    return index\n",
    "\n",
    "def load_embeddings(file_name=\"faiss.index\"):\n",
    "    return faiss.read_index(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15466844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_embeddings(query, index, text_chunks, sources, top_k=3, model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(input=[query], model=model)\n",
    "    query_embedding = np.array(response.data[0].embedding, dtype='float32').reshape(1, -1)\n",
    "    _, indices = index.search(query_embedding, top_k)\n",
    "    return [(text_chunks[i], sources[i]) for i in indices[0]]\n",
    "\n",
    "def get_chatgpt_response(query, relevant_chunks, model=\"gpt-4o\"):\n",
    "    context = \"\\n\\n---\\n\\n\".join([chunk for chunk, _ in relevant_chunks])\n",
    "    prompt = f\"Using the context, answer the question:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff4dee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_latex_delimiters(text):\n",
    "    text = re.sub(r'\\\\\\[(.*?)\\\\\\]', r'$$\\1$$', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\\\\\((.*?)\\\\\\)', r'$\\1$', text, flags=re.DOTALL)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7029953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List your PDF files\n",
    "pdf_files = [\n",
    "    \"doc1.pdf\",\n",
    "    \"doc2.pdf\"\n",
    "    ]  # Update this list\n",
    "\n",
    "# Initialize database\n",
    "conn = init_db()\n",
    "\n",
    "# Process PDFs and store chunks\n",
    "chunks, sources = process_pdfs(pdf_files)\n",
    "store_chunks(conn, chunks, sources)\n",
    "\n",
    "# Generate and store embeddings\n",
    "embeddings = create_embeddings(chunks)\n",
    "index = store_embeddings(embeddings)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b29efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine the apparent tangential speed of the sources as seen from Earth, we need to convert the angular separation into a physical distance and then calculate the speed.\n",
       "\n",
       "Given:\n",
       "- Distance to the galaxy, $ d_A = 100 $ Mpc.\n",
       "- Angular separation for one source, $ \\theta_1 = 1.00 $ milliarcseconds.\n",
       "- Angular separation for the other source, $ \\theta_2 = 0.27 $ milliarcseconds.\n",
       "- Time interval, $ \\Delta t = 1 $ year.\n",
       "\n",
       "First, convert the angular separations from milliarcseconds to radians:\n",
       "1 milliarcsecond = $ 1 \\times 10^{-3} $ arcseconds = $ 1 \\times 10^{-3} \\times \\frac{\\pi}{180 \\times 3600} $ radians.\n",
       "\n",
       "For the first source:\n",
       "$$ \\theta_1 = 1.00 \\times 10^{-3} \\times \\frac{\\pi}{180 \\times 3600} \\, \\text{radians} $$\n",
       "\n",
       "For the second source:\n",
       "$$ \\theta_2 = 0.27 \\times 10^{-3} \\times \\frac{\\pi}{180 \\times 3600} \\, \\text{radians} $$\n",
       "\n",
       "Next, calculate the physical distance traveled by each source using the formula $ l = \\theta \\times d_A $.\n",
       "\n",
       "For the first source:\n",
       "$$ l_1 = \\theta_1 \\times d_A $$\n",
       "\n",
       "For the second source:\n",
       "$$ l_2 = \\theta_2 \\times d_A $$\n",
       "\n",
       "Convert the distance to meters (1 Mpc = $ 3.086 \\times 10^{22} $ meters):\n",
       "$$ d_A = 100 \\times 3.086 \\times 10^{22} \\, \\text{meters} $$\n",
       "\n",
       "Calculate the physical distances:\n",
       "$$ l_1 = \\left(1.00 \\times 10^{-3} \\times \\frac{\\pi}{180 \\times 3600}\\right) \\times (100 \\times 3.086 \\times 10^{22}) $$\n",
       "$$ l_2 = \\left(0.27 \\times 10^{-3} \\times \\frac{\\pi}{180 \\times 3600}\\right) \\times (100 \\times 3.086 \\times 10^{22}) $$\n",
       "\n",
       "Finally, calculate the apparent tangential speeds:\n",
       "$$ v_1 = \\frac{l_1}{\\Delta t} $$\n",
       "$$ v_2 = \\frac{l_2}{\\Delta t} $$\n",
       "\n",
       "Since $\\Delta t = 1$ year, convert it to seconds (1 year = $ 3.156 \\times 10^7 $ seconds).\n",
       "\n",
       "$$ v_1 = \\frac{l_1}{3.156 \\times 10^7} $$\n",
       "$$ v_2 = \\frac{l_2}{3.156 \\times 10^7} $$\n",
       "\n",
       "These calculations will give you the apparent tangential speeds of the two sources in meters per second."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"chunks.db\")\n",
    "index = load_embeddings(\"faiss.index\")\n",
    "\n",
    "chunk_data = retrieve_chunks(conn)\n",
    "chunk_ids, chunk_sources, chunk_texts = zip(*chunk_data)\n",
    "\n",
    "query = \"Explain cosmological redshift equations\"\n",
    "relevant_chunks = search_embeddings(query, index, chunk_texts, chunk_sources, top_k=3)\n",
    "answer = get_chatgpt_response(query, relevant_chunks)\n",
    "\n",
    "answer_fixed = fix_latex_delimiters(answer)\n",
    "display(Markdown(answer_fixed))\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
